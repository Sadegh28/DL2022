{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dtaset\n",
    "DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Datasets & DataLoaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides two data primitives: ``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``\n",
    "that allow you to use pre-loaded datasets as well as your own data.\n",
    "* ``Dataset`` stores the samples and their corresponding labels,\n",
    "* ``DataLoader`` wraps an iterable around the ``Dataset`` to enable easy access to the samples.\n",
    "* PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass ``torch.utils.data.Dataset`` and implement functions specific to the particular data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:  Fashion-MNIST Dataset\n",
    "\n",
    "* Fashion-MNIST is a dataset of images consisting of 60,000 training examples and 10,000 test examples.\n",
    "* Each example comprises a 28Ã—28 grayscale image and an associated label from one of 10 classes.\n",
    "\n",
    "We load the [FashionMNIST Dataset](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) with the following parameters:\n",
    " - ``root`` is the path where the train/test data is stored,\n",
    " - ``train`` specifies training or test dataset,\n",
    " - ``download=True`` downloads the data from the internet if it's not available at ``root``.\n",
    " - ``transform`` and ``target_transform`` specify the feature and label transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating and Visualizing the Dataset\n",
    "\n",
    "We can index ``Datasets`` manually like a list: ``training_data[index]``.\n",
    "We use ``matplotlib`` to visualize some samples in our training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Dataset\n",
    "\n",
    "* A custom Dataset class must inherit the ``Dataset`` class and implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example: The Iris Dataset\n",
    "\n",
    "**Iris**: The data report four characteristics (sepal width, sepal length, petal width and petal length) of three species of Iris flower. \n",
    "\n",
    "Species_No: Flower species as a code (1: setosa, 2: versicolor, 3: verginica)\n",
    "Species_Name: Species name \n",
    "Petal_Width: Petal Width \n",
    "Petal_Length: Petal Length \n",
    "Sepal_Width: Sepal Width \n",
    "Sepal_Length: Sepal Length\n",
    "\n",
    "![Iris Dataset](data/Iris/iris_image.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Iris/Iris1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as p\n",
    "\n",
    "df = pd.read_csv(\"data/Iris/Iris1.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, file, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(file)\n",
    "        self.y = self.data['Species_No']-1\n",
    "        self.X = self.data[['Petal_width','Petal_length','Sepal_width','Sepal_length']]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y[idx]\n",
    "        x = self.X.iloc[idx,:].to_numpy()\n",
    "        if self.transform:\n",
    "            image = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(y)\n",
    "        return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example: The FashionMNIST Dataset\n",
    "the FashionMNIST images are stored in a directory ``img_dir``, and their labels are stored separately in a CSV file ``annotations_file``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting your data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "iris_dataset = IrisDataset(\"data/Iris/Iris1.csv\")\n",
    "iris_dataset_train, iris_dataset_test = random_split(iris_dataset, [100, 50], generator=torch.Generator().manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your data for training with DataLoaders\n",
    "The ``Dataset`` retrieves our dataset's features and labels one sample at a time. While training a model, we typically want to pass samples in \"minibatches\" and reshuffle the data at every epoch to reduce model overfitting\n",
    "\n",
    "``DataLoader`` is an iterable that abstracts this complexity for us in an easy API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "iris_dataset_train_dataLoader = DataLoader(iris_dataset_train, batch_size=5, shuffle=True)\n",
    "iris_dataset_test_dataLoader = DataLoader(iris_dataset_test, batch_size=5, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through the DataLoader\n",
    "\n",
    "* We have loaded that dataset into the ``DataLoader`` and can iterate through the dataset as needed.\n",
    "* Each iteration below returns a batch of ``X`` and ``y`` (containing ``batch_size=12`` features and labels respectively).\n",
    "* Because we specified ``shuffle=True``, after we iterate over all batches the data is shuffled \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8000, 6.0000, 3.2000, 7.2000],\n",
      "        [1.0000, 3.7000, 2.4000, 5.5000],\n",
      "        [1.8000, 5.5000, 3.1000, 6.4000],\n",
      "        [1.0000, 3.5000, 2.6000, 5.7000],\n",
      "        [2.5000, 5.7000, 3.3000, 6.7000]], dtype=torch.float64)\n",
      "tensor([2, 1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_X, batch_y = next(iter(iris_dataset_test_dataLoader))\n",
    "print(batch_X)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "* Neural networks comprise of layers/modules that perform operations on data.\n",
    "* The ``torch.nn`` namespace provides all the building blocks you need to build your own neural network.\n",
    "* Every module in PyTorch subclasses the ``nn.Module``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device for Training\n",
    "We want to be able to train our model on a hardware accelerator like the GPU,\n",
    "if it is available. Let's check to see if ``torch.cuda`` is available, else we\n",
    "continue to use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Class\n",
    "* We define our neural network by subclassing ``nn.Module``\n",
    "* We initialize the neural network layers in ``__init__``.\n",
    "* Every ``nn.Module`` subclass implements the operations on input data in the ``forward`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_layers = nn.Sequential(\n",
    "            nn.Linear(4, 50, bias = False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20, bias = False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3, bias = False),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return  self.linear_relu_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=50, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=20, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m----> 3\u001b[0m \u001b[43miris_dataset_test_dataLoader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "iris_dataset_test_dataLoader.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets test the model**\n",
    "\n",
    "$softmax(x) = \\frac{e^{x_i}}{\\sum_{j=1}^{K}e^{x_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Output: tensor([[ 0.0828, -0.4290,  0.7035],\n",
      "        [ 0.0388, -0.2655,  0.5551],\n",
      "        [ 0.0841, -0.3984,  0.6242],\n",
      "        [ 0.0367, -0.2511,  0.5775],\n",
      "        [ 0.1006, -0.4162,  0.6329]], grad_fn=<MmBackward>)\n",
      "Probabilities: tensor([[0.2891, 0.1733, 0.5377],\n",
      "        [0.2929, 0.2161, 0.4910],\n",
      "        [0.3000, 0.1852, 0.5149],\n",
      "        [0.2884, 0.2163, 0.4953],\n",
      "        [0.3031, 0.1808, 0.5161]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted class: tensor([3, 3, 3, 3, 3])\n",
      "True class: tensor([2, 1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = model(batch_X.float().to(device))\n",
    "print(f'Network Output: {results}')\n",
    "\n",
    "#convert the results to probabilities\n",
    "pred_probab = nn.Softmax(dim=1)(results)\n",
    "print(f'Probabilities: {pred_probab}')\n",
    "\n",
    "y_pred = pred_probab.argmax(1)+1\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "print(f'True class: {batch_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "In this example, we iterate over each parameter, and print its size and a preview of its values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (linear_relu_layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=50, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=20, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_layers.0.weight | Size: torch.Size([50, 4]) | Values : tensor([[ 0.1580,  0.4828, -0.1613,  0.0705],\n",
      "        [ 0.2493,  0.0956,  0.4601, -0.4530]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_layers.2.weight | Size: torch.Size([20, 50]) | Values : tensor([[ 0.0067, -0.0611,  0.1044, -0.1220, -0.1394,  0.0104, -0.1289, -0.0418,\n",
      "         -0.0400,  0.1093,  0.0881, -0.1370,  0.1011, -0.0787, -0.0877,  0.0903,\n",
      "         -0.0976,  0.0660, -0.0374,  0.1394,  0.1110,  0.0069,  0.0368,  0.0893,\n",
      "          0.0881,  0.1096, -0.1156, -0.1022, -0.1310,  0.0497, -0.0903, -0.0558,\n",
      "         -0.0796,  0.0840,  0.0678,  0.0910, -0.0441, -0.1111,  0.0020, -0.0564,\n",
      "         -0.0821, -0.0356,  0.0922,  0.0080,  0.1089,  0.0570, -0.0957,  0.1160,\n",
      "         -0.0885, -0.0175],\n",
      "        [-0.1083, -0.1012,  0.0638, -0.0865, -0.0947,  0.1158,  0.1066, -0.1286,\n",
      "          0.1159, -0.0546,  0.0375,  0.0561,  0.0154,  0.0005, -0.0925,  0.0034,\n",
      "         -0.0938,  0.0332, -0.0218, -0.0137, -0.0668, -0.0937, -0.1020,  0.0950,\n",
      "         -0.0394, -0.1400, -0.0528,  0.0527,  0.0678, -0.0919, -0.0526,  0.1066,\n",
      "          0.0469,  0.0978, -0.0100,  0.1160,  0.0769, -0.1162, -0.0670, -0.1129,\n",
      "          0.0438, -0.0197,  0.0131, -0.0025, -0.0432, -0.0241, -0.0421, -0.1302,\n",
      "          0.0049, -0.1001]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_layers.4.weight | Size: torch.Size([3, 20]) | Values : tensor([[-0.0985, -0.1661,  0.0943, -0.0043, -0.0260,  0.1909,  0.0035, -0.2019,\n",
      "         -0.1503,  0.2045, -0.0546,  0.0194,  0.2110,  0.0179, -0.1553,  0.1652,\n",
      "          0.1514,  0.1487, -0.2023,  0.0295],\n",
      "        [-0.1466,  0.1019, -0.0125, -0.1353,  0.1724,  0.2057,  0.1744, -0.0449,\n",
      "          0.1760, -0.1630, -0.0512,  0.0481, -0.0381, -0.1000,  0.1452, -0.1693,\n",
      "         -0.0559, -0.1956, -0.1746,  0.1032]], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model (parameter optimization) \n",
    "1. define a loss function \n",
    "2. define an optimizer\n",
    "3. train the model \n",
    "4. test the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a loss function \n",
    "* **Loss function** measures the degree of dissimilarity of obtained result to the target value\n",
    "* We want to minimize the loss function during training. \n",
    "* To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
    "* Common loss functions for classification include ``nn.MSELoss`` (Mean Square Error), and ``nn.CrossEntropyLoss`` (Cross Entropy Loss)\n",
    "\n",
    "* **MSELoss:**\n",
    "$L(o,y) = \\frac{1}{N}(l_1+ l_2+ \\dots+ l_N), l_i = (o_i-y_i)^2$\n",
    "\n",
    "* **CrossEntropyLoss:**\n",
    "$L(o,y) = \\sum_{i=1}^{N}(l_1, l_2, \\dots, l_N), l_i = -y_i\\log(o_i)$ and $o_i$ the softmax value (the probability value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an optimizer\n",
    "\n",
    "* Optimization is the process of adjusting model parameters to reduce model error in each training step.\n",
    "* Here, we use the SGD optimizer\n",
    "* There are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.350748  [    0/  100]\n",
      "loss: 1.224465  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.080114 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.048687  [    0/  100]\n",
      "loss: 1.265125  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.065733 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.145473  [    0/  100]\n",
      "loss: 1.169921  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.056608 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.980467  [    0/  100]\n",
      "loss: 1.038061  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.049337 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.173302  [    0/  100]\n",
      "loss: 1.106023  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.042644 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.108742  [    0/  100]\n",
      "loss: 1.052057  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.036560 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.096596  [    0/  100]\n",
      "loss: 1.045635  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.030931 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.036140  [    0/  100]\n",
      "loss: 1.104165  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.024751 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.024533  [    0/  100]\n",
      "loss: 1.078356  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.020296 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.966105  [    0/  100]\n",
      "loss: 1.036954  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.014778 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.057654  [    0/  100]\n",
      "loss: 1.038110  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.009725 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.945986  [    0/  100]\n",
      "loss: 1.076959  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.004675 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.036498  [    0/  100]\n",
      "loss: 0.995816  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 0.999599 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.997344  [    0/  100]\n",
      "loss: 0.977694  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 0.994683 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.005819  [    0/  100]\n",
      "loss: 0.980081  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.989231 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.005548  [    0/  100]\n",
      "loss: 1.039649  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.983543 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.963986  [    0/  100]\n",
      "loss: 1.043604  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.978112 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.012861  [    0/  100]\n",
      "loss: 1.042642  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.972872 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.018135  [    0/  100]\n",
      "loss: 0.962147  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.968518 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.008495  [    0/  100]\n",
      "loss: 1.015572  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.963061 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.975099  [    0/  100]\n",
      "loss: 1.004566  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.958286 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.000852  [    0/  100]\n",
      "loss: 0.952259  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.952575 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.943436  [    0/  100]\n",
      "loss: 1.008578  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.948176 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.975844  [    0/  100]\n",
      "loss: 0.923509  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.942080 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.920907  [    0/  100]\n",
      "loss: 0.922328  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.935631 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.941371  [    0/  100]\n",
      "loss: 0.935282  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.930667 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.923279  [    0/  100]\n",
      "loss: 0.910151  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.925110 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.923834  [    0/  100]\n",
      "loss: 0.926357  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.919261 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.925558  [    0/  100]\n",
      "loss: 1.002067  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.913865 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.953749  [    0/  100]\n",
      "loss: 0.928907  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.908556 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.914409  [    0/  100]\n",
      "loss: 0.880474  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.902426 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.952458  [    0/  100]\n",
      "loss: 0.915641  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.895324 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.939343  [    0/  100]\n",
      "loss: 0.887112  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.888726 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.907535  [    0/  100]\n",
      "loss: 0.881982  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.883042 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.819708  [    0/  100]\n",
      "loss: 0.916551  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.876609 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.873879  [    0/  100]\n",
      "loss: 0.908570  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.871760 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.893929  [    0/  100]\n",
      "loss: 0.906839  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.865062 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.866621  [    0/  100]\n",
      "loss: 0.828349  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.858237 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.834724  [    0/  100]\n",
      "loss: 0.840964  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.851965 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.840216  [    0/  100]\n",
      "loss: 0.830625  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.846103 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.900583  [    0/  100]\n",
      "loss: 0.837422  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.840808 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.851053  [    0/  100]\n",
      "loss: 0.923343  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.833542 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.795582  [    0/  100]\n",
      "loss: 0.917939  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.828128 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.848544  [    0/  100]\n",
      "loss: 0.781430  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.820994 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.827913  [    0/  100]\n",
      "loss: 0.841827  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.812576 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.757452  [    0/  100]\n",
      "loss: 0.849689  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.806981 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.805123  [    0/  100]\n",
      "loss: 0.798753  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.800304 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.872892  [    0/  100]\n",
      "loss: 0.732660  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.793354 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.770019  [    0/  100]\n",
      "loss: 0.850327  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.787269 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.794011  [    0/  100]\n",
      "loss: 0.770287  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.780835 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.729890  [    0/  100]\n",
      "loss: 0.777911  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.774545 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.759823  [    0/  100]\n",
      "loss: 0.734868  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.768118 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.758505  [    0/  100]\n",
      "loss: 0.743638  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.760297 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.769471  [    0/  100]\n",
      "loss: 0.743991  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.753076 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.706397  [    0/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.780287  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.747569 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.743962  [    0/  100]\n",
      "loss: 0.673987  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.741442 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.714585  [    0/  100]\n",
      "loss: 0.633278  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.734288 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.674667  [    0/  100]\n",
      "loss: 0.649854  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.727677 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.676816  [    0/  100]\n",
      "loss: 0.664502  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.720965 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.806742  [    0/  100]\n",
      "loss: 0.681738  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.715145 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.746562  [    0/  100]\n",
      "loss: 0.627323  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.708051 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.688375  [    0/  100]\n",
      "loss: 0.693213  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.701482 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.813566  [    0/  100]\n",
      "loss: 0.551812  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.696044 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.712549  [    0/  100]\n",
      "loss: 0.626747  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.690100 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.540601  [    0/  100]\n",
      "loss: 0.748524  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.685316 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.699132  [    0/  100]\n",
      "loss: 0.460657  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.679144 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.603631  [    0/  100]\n",
      "loss: 0.619277  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.673948 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.792807  [    0/  100]\n",
      "loss: 0.647708  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.668545 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.651852  [    0/  100]\n",
      "loss: 0.702417  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.663483 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.595755  [    0/  100]\n",
      "loss: 0.736025  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.657225 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.645372  [    0/  100]\n",
      "loss: 0.747695  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.650534 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.664351  [    0/  100]\n",
      "loss: 0.650806  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.646433 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.704740  [    0/  100]\n",
      "loss: 0.608814  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.641152 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.459023  [    0/  100]\n",
      "loss: 0.517342  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.637240 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.677030  [    0/  100]\n",
      "loss: 0.638925  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.632254 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.581744  [    0/  100]\n",
      "loss: 0.653335  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.625781 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.558540  [    0/  100]\n",
      "loss: 0.413015  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.621449 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.547319  [    0/  100]\n",
      "loss: 0.503591  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.616052 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.550551  [    0/  100]\n",
      "loss: 0.561375  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.613450 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.481029  [    0/  100]\n",
      "loss: 0.435535  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.609996 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.561719  [    0/  100]\n",
      "loss: 0.477576  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.603866 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.592645  [    0/  100]\n",
      "loss: 0.464783  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.598643 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.620582  [    0/  100]\n",
      "loss: 0.632297  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.595288 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.509366  [    0/  100]\n",
      "loss: 0.565470  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.591653 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.663640  [    0/  100]\n",
      "loss: 0.645387  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.587188 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.416369  [    0/  100]\n",
      "loss: 0.492495  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.583548 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.438935  [    0/  100]\n",
      "loss: 0.612640  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.579730 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.620084  [    0/  100]\n",
      "loss: 0.501811  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.576474 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.494951  [    0/  100]\n",
      "loss: 0.559129  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.572250 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.559925  [    0/  100]\n",
      "loss: 0.539158  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.567812 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.420186  [    0/  100]\n",
      "loss: 0.757535  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.565414 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.559346  [    0/  100]\n",
      "loss: 0.639039  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.562699 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.456866  [    0/  100]\n",
      "loss: 0.546953  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.558377 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.289577  [    0/  100]\n",
      "loss: 0.397655  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.555234 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.434771  [    0/  100]\n",
      "loss: 0.571962  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.552523 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.409736  [    0/  100]\n",
      "loss: 0.493253  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.549512 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.444398  [    0/  100]\n",
      "loss: 0.253678  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.548361 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.512048  [    0/  100]\n",
      "loss: 0.426872  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.543078 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.445661  [    0/  100]\n",
      "loss: 0.378400  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.537884 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.486311  [    0/  100]\n",
      "loss: 0.260116  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.537220 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.407269  [    0/  100]\n",
      "loss: 0.441126  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.533730 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.611129  [    0/  100]\n",
      "loss: 0.414803  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.531393 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.459143  [    0/  100]\n",
      "loss: 0.456183  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.527444 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.374545  [    0/  100]\n",
      "loss: 0.353552  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.525011 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.412917  [    0/  100]\n",
      "loss: 0.585819  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.521947 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.334634  [    0/  100]\n",
      "loss: 0.486812  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.520565 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.403459  [    0/  100]\n",
      "loss: 0.478388  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.516835 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.640310  [    0/  100]\n",
      "loss: 0.532549  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.513775 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.432410  [    0/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.506556  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.512244 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.457569  [    0/  100]\n",
      "loss: 0.248022  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.510711 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.419986  [    0/  100]\n",
      "loss: 0.476465  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.507618 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.442560  [    0/  100]\n",
      "loss: 0.436329  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.504943 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.457716  [    0/  100]\n",
      "loss: 0.429396  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.503407 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.525003  [    0/  100]\n",
      "loss: 0.409390  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.503390 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.450649  [    0/  100]\n",
      "loss: 0.283417  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.500628 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.335079  [    0/  100]\n",
      "loss: 0.569962  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.495995 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.658162  [    0/  100]\n",
      "loss: 0.341459  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.492928 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.193900  [    0/  100]\n",
      "loss: 0.357689  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.492512 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.567074  [    0/  100]\n",
      "loss: 0.363021  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.489709 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.417877  [    0/  100]\n",
      "loss: 0.222236  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.486350 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.332614  [    0/  100]\n",
      "loss: 0.322305  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.485232 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.528102  [    0/  100]\n",
      "loss: 0.373596  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.483416 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.500649  [    0/  100]\n",
      "loss: 0.321306  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.482096 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.615423  [    0/  100]\n",
      "loss: 0.449475  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.481990 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.442892  [    0/  100]\n",
      "loss: 0.400006  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.478861 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.248341  [    0/  100]\n",
      "loss: 0.379859  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.476018 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.307202  [    0/  100]\n",
      "loss: 0.446014  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.474498 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.618545  [    0/  100]\n",
      "loss: 0.488340  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.474003 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.413263  [    0/  100]\n",
      "loss: 0.403945  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.471839 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.419321  [    0/  100]\n",
      "loss: 0.666709  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.467538 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.424079  [    0/  100]\n",
      "loss: 0.194990  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.464265 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.408678  [    0/  100]\n",
      "loss: 0.465580  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.462310 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.331348  [    0/  100]\n",
      "loss: 0.400716  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.461122 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.352363  [    0/  100]\n",
      "loss: 0.155326  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.459655 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.447333  [    0/  100]\n",
      "loss: 0.535833  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.458422 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.391677  [    0/  100]\n",
      "loss: 0.554874  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.455673 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.256590  [    0/  100]\n",
      "loss: 0.529673  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.453873 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.510998  [    0/  100]\n",
      "loss: 0.435415  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.453083 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.455589  [    0/  100]\n",
      "loss: 0.467909  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.451041 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.419530  [    0/  100]\n",
      "loss: 0.232681  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.450637 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.450962  [    0/  100]\n",
      "loss: 0.396512  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.447970 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.216176  [    0/  100]\n",
      "loss: 0.322130  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.447913 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.434410  [    0/  100]\n",
      "loss: 0.438855  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.445766 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.264798  [    0/  100]\n",
      "loss: 0.250960  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.446347 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.594229  [    0/  100]\n",
      "loss: 0.451022  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.439117 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.255907  [    0/  100]\n",
      "loss: 0.268851  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.439248 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.462463  [    0/  100]\n",
      "loss: 0.383029  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.438958 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.288956  [    0/  100]\n",
      "loss: 0.428232  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.437625 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.325764  [    0/  100]\n",
      "loss: 0.302815  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.438138 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.520906  [    0/  100]\n",
      "loss: 0.417643  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.432307 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.432504  [    0/  100]\n",
      "loss: 0.364404  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.432627 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.397567  [    0/  100]\n",
      "loss: 0.295417  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.429567 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.446924  [    0/  100]\n",
      "loss: 0.252813  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.426558 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.280551  [    0/  100]\n",
      "loss: 0.408506  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.426442 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.487117  [    0/  100]\n",
      "loss: 0.425899  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.422712 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.263815  [    0/  100]\n",
      "loss: 0.410809  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.421451 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.356268  [    0/  100]\n",
      "loss: 0.191781  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.421172 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.220004  [    0/  100]\n",
      "loss: 0.511160  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.419518 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.314480  [    0/  100]\n",
      "loss: 0.383486  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.416788 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.275821  [    0/  100]\n",
      "loss: 0.422535  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.415449 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.405259  [    0/  100]\n",
      "loss: 0.467073  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.414706 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.465429  [    0/  100]\n",
      "loss: 0.496968  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.412186 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.228499  [    0/  100]\n",
      "loss: 0.403135  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.412453 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.429350  [    0/  100]\n",
      "loss: 0.130031  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.410442 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.231851  [    0/  100]\n",
      "loss: 0.343805  [   50/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.412852 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.319348  [    0/  100]\n",
      "loss: 0.372933  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.409908 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.385267  [    0/  100]\n",
      "loss: 0.274788  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.403737 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.325144  [    0/  100]\n",
      "loss: 0.374497  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.402271 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.296812  [    0/  100]\n",
      "loss: 0.325708  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.400511 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.396120  [    0/  100]\n",
      "loss: 0.274912  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.399992 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.486834  [    0/  100]\n",
      "loss: 0.191909  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.398126 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.197474  [    0/  100]\n",
      "loss: 0.373259  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.397352 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.420169  [    0/  100]\n",
      "loss: 0.396515  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.395772 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.234058  [    0/  100]\n",
      "loss: 0.267047  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.395585 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.399916  [    0/  100]\n",
      "loss: 0.349159  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.392250 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.313631  [    0/  100]\n",
      "loss: 0.342281  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.392684 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.386626  [    0/  100]\n",
      "loss: 0.354889  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.389194 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.478648  [    0/  100]\n",
      "loss: 0.187367  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.387974 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.161456  [    0/  100]\n",
      "loss: 0.246663  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.388578 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.296451  [    0/  100]\n",
      "loss: 0.313796  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.386956 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.249992  [    0/  100]\n",
      "loss: 0.369299  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.383645 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.284447  [    0/  100]\n",
      "loss: 0.215679  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.381181 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.322249  [    0/  100]\n",
      "loss: 0.333323  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.378979 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.291893  [    0/  100]\n",
      "loss: 0.330003  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.378949 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.267156  [    0/  100]\n",
      "loss: 0.129308  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.376216 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.325349  [    0/  100]\n",
      "loss: 0.319258  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.376261 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.281522  [    0/  100]\n",
      "loss: 0.297384  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.373661 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.349133  [    0/  100]\n",
      "loss: 0.193901  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.372851 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.253684  [    0/  100]\n",
      "loss: 0.380511  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.372468 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.406224  [    0/  100]\n",
      "loss: 0.251424  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.368597 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.257249  [    0/  100]\n",
      "loss: 0.173018  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.368322 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.302123  [    0/  100]\n",
      "loss: 0.127561  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.367289 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.301860  [    0/  100]\n",
      "loss: 0.120326  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.364245 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.293800  [    0/  100]\n",
      "loss: 0.328890  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.362802 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.254486  [    0/  100]\n",
      "loss: 0.289293  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.363875 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.339063  [    0/  100]\n",
      "loss: 0.292292  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.362957 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.407291  [    0/  100]\n",
      "loss: 0.174989  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.362691 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.216012  [    0/  100]\n",
      "loss: 0.392509  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.361805 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.272438  [    0/  100]\n",
      "loss: 0.162275  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.357931 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.232851  [    0/  100]\n",
      "loss: 0.260962  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.356272 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.172400  [    0/  100]\n",
      "loss: 0.430570  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.354193 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.217404  [    0/  100]\n",
      "loss: 0.322983  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.353746 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.345956  [    0/  100]\n",
      "loss: 0.236830  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.351130 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.267776  [    0/  100]\n",
      "loss: 0.191009  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.353609 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.269599  [    0/  100]\n",
      "loss: 0.461873  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.348744 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.322011  [    0/  100]\n",
      "loss: 0.304260  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.348307 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.186092  [    0/  100]\n",
      "loss: 0.229431  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.344822 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.295049  [    0/  100]\n",
      "loss: 0.326603  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.342991 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.255634  [    0/  100]\n",
      "loss: 0.047111  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.342408 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.039173  [    0/  100]\n",
      "loss: 0.410723  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.342153 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.240505  [    0/  100]\n",
      "loss: 0.368219  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.339840 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.220249  [    0/  100]\n",
      "loss: 0.339523  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.340083 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.268100  [    0/  100]\n",
      "loss: 0.277136  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.337878 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.088998  [    0/  100]\n",
      "loss: 0.162653  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.335980 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.274220  [    0/  100]\n",
      "loss: 0.196420  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.336404 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.159342  [    0/  100]\n",
      "loss: 0.170895  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.337995 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.336881  [    0/  100]\n",
      "loss: 0.081119  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.332956 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.263002  [    0/  100]\n",
      "loss: 0.295126  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.332737 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.218190  [    0/  100]\n",
      "loss: 0.087345  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.331815 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.102457  [    0/  100]\n",
      "loss: 0.191168  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.329974 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.227424  [    0/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.216860  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.328027 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.148824  [    0/  100]\n",
      "loss: 0.301369  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.329730 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.319111  [    0/  100]\n",
      "loss: 0.202797  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.328110 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.265621  [    0/  100]\n",
      "loss: 0.141473  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.324616 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.111529  [    0/  100]\n",
      "loss: 0.278279  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.324785 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.090050  [    0/  100]\n",
      "loss: 0.251237  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.322272 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.229983  [    0/  100]\n",
      "loss: 0.147838  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.319737 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.222078  [    0/  100]\n",
      "loss: 0.199225  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.318570 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.335078  [    0/  100]\n",
      "loss: 0.450820  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.322788 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.325369  [    0/  100]\n",
      "loss: 0.154510  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.317022 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.138763  [    0/  100]\n",
      "loss: 0.172353  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.316486 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.307481  [    0/  100]\n",
      "loss: 0.198135  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.314363 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.113653  [    0/  100]\n",
      "loss: 0.300557  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.312998 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.195086  [    0/  100]\n",
      "loss: 0.194655  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.312568 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.173088  [    0/  100]\n",
      "loss: 0.194636  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.312801 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.266010  [    0/  100]\n",
      "loss: 0.157462  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.311424 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.180979  [    0/  100]\n",
      "loss: 0.272297  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.308884 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.204784  [    0/  100]\n",
      "loss: 0.159859  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.307843 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.283768  [    0/  100]\n",
      "loss: 0.172287  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.309473 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.262673  [    0/  100]\n",
      "loss: 0.384917  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.306083 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.187675  [    0/  100]\n",
      "loss: 0.146818  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.303531 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.275739  [    0/  100]\n",
      "loss: 0.133367  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.305275 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.430954  [    0/  100]\n",
      "loss: 0.224259  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.302465 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.098402  [    0/  100]\n",
      "loss: 0.268501  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.301558 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.184152  [    0/  100]\n",
      "loss: 0.130168  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.304760 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.194390  [    0/  100]\n",
      "loss: 0.078386  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.301150 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.143336  [    0/  100]\n",
      "loss: 0.301483  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.297861 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.204185  [    0/  100]\n",
      "loss: 0.366693  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.296693 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.171266  [    0/  100]\n",
      "loss: 0.244739  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.300992 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.378865  [    0/  100]\n",
      "loss: 0.137099  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.297550 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.095192  [    0/  100]\n",
      "loss: 0.303971  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.293932 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.339610  [    0/  100]\n",
      "loss: 0.222398  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.294128 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.163064  [    0/  100]\n",
      "loss: 0.117361  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.291366 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.202876  [    0/  100]\n",
      "loss: 0.175858  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.290059 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.143107  [    0/  100]\n",
      "loss: 0.107366  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.290025 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.287654  [    0/  100]\n",
      "loss: 0.117203  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.292545 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.166309  [    0/  100]\n",
      "loss: 0.407983  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.292445 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.135303  [    0/  100]\n",
      "loss: 0.166737  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.287902 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.165333  [    0/  100]\n",
      "loss: 0.070809  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.287378 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.156326  [    0/  100]\n",
      "loss: 0.187091  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.288438 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.202360  [    0/  100]\n",
      "loss: 0.157327  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.285544 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.237239  [    0/  100]\n",
      "loss: 0.145770  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.286083 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.136766  [    0/  100]\n",
      "loss: 0.162726  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.283452 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.060834  [    0/  100]\n",
      "loss: 0.123652  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.281267 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.095905  [    0/  100]\n",
      "loss: 0.157475  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.280148 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.051486  [    0/  100]\n",
      "loss: 0.156537  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.278664 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.142974  [    0/  100]\n",
      "loss: 0.181787  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.279904 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.132540  [    0/  100]\n",
      "loss: 0.390987  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.281078 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.172972  [    0/  100]\n",
      "loss: 0.168074  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.277239 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.262897  [    0/  100]\n",
      "loss: 0.225179  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.284248 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.144711  [    0/  100]\n",
      "loss: 0.194154  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.279352 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.137484  [    0/  100]\n",
      "loss: 0.114768  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.273692 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.125212  [    0/  100]\n",
      "loss: 0.187359  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.272751 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.084934  [    0/  100]\n",
      "loss: 0.210142  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.272032 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.080825  [    0/  100]\n",
      "loss: 0.163695  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.270805 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.189804  [    0/  100]\n",
      "loss: 0.334064  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.270847 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.049005  [    0/  100]\n",
      "loss: 0.156055  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.270346 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.167867  [    0/  100]\n",
      "loss: 0.209725  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.268392 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.311807  [    0/  100]\n",
      "loss: 0.258520  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.268884 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.092709  [    0/  100]\n",
      "loss: 0.227621  [   50/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.267165 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.113491  [    0/  100]\n",
      "loss: 0.194203  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.266652 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.136045  [    0/  100]\n",
      "loss: 0.219050  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.270838 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.227147  [    0/  100]\n",
      "loss: 0.141767  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.265210 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.094362  [    0/  100]\n",
      "loss: 0.257853  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.263652 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.158204  [    0/  100]\n",
      "loss: 0.082406  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.264378 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.135867  [    0/  100]\n",
      "loss: 0.383964  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.263363 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.145065  [    0/  100]\n",
      "loss: 0.218843  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.265474 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.098140  [    0/  100]\n",
      "loss: 0.175755  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.263242 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.336237  [    0/  100]\n",
      "loss: 0.153638  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.262115 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.146174  [    0/  100]\n",
      "loss: 0.088469  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.259206 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.163228  [    0/  100]\n",
      "loss: 0.167828  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.261997 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.107693  [    0/  100]\n",
      "loss: 0.216033  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.257733 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.086187  [    0/  100]\n",
      "loss: 0.104757  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.258202 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.186893  [    0/  100]\n",
      "loss: 0.046301  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.257637 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.104785  [    0/  100]\n",
      "loss: 0.272697  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.256514 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.148954  [    0/  100]\n",
      "loss: 0.075258  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.255133 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.152406  [    0/  100]\n",
      "loss: 0.088359  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.255199 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.235389  [    0/  100]\n",
      "loss: 0.141990  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.253301 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.151676  [    0/  100]\n",
      "loss: 0.109188  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.255312 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.203376  [    0/  100]\n",
      "loss: 0.240274  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.252940 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.104200  [    0/  100]\n",
      "loss: 0.160312  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.251580 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.092191  [    0/  100]\n",
      "loss: 0.036994  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.250720 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.055724  [    0/  100]\n",
      "loss: 0.193054  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.251510 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.069098  [    0/  100]\n",
      "loss: 0.076056  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.249770 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.152518  [    0/  100]\n",
      "loss: 0.130014  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.251090 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.188951  [    0/  100]\n",
      "loss: 0.274747  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.251230 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.100370  [    0/  100]\n",
      "loss: 0.146100  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.247992 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.147970  [    0/  100]\n",
      "loss: 0.147077  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.246871 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.230622  [    0/  100]\n",
      "loss: 0.067234  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.246187 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.103389  [    0/  100]\n",
      "loss: 0.210587  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.247038 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.101877  [    0/  100]\n",
      "loss: 0.155633  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.249043 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.290019  [    0/  100]\n",
      "loss: 0.184302  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.244710 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.089221  [    0/  100]\n",
      "loss: 0.202968  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.244236 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.067972  [    0/  100]\n",
      "loss: 0.049353  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.243505 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.194313  [    0/  100]\n",
      "loss: 0.038598  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.243945 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.056054  [    0/  100]\n",
      "loss: 0.149558  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.242673 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.229944  [    0/  100]\n",
      "loss: 0.106175  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.243695 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.105507  [    0/  100]\n",
      "loss: 0.177141  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.242531 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.139555  [    0/  100]\n",
      "loss: 0.103483  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.240501 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.129304  [    0/  100]\n",
      "loss: 0.053654  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.240450 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.147162  [    0/  100]\n",
      "loss: 0.311148  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.241137 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.211972  [    0/  100]\n",
      "loss: 0.062793  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.238426 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.090968  [    0/  100]\n",
      "loss: 0.101524  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.237953 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.179662  [    0/  100]\n",
      "loss: 0.063586  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.237459 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.124435  [    0/  100]\n",
      "loss: 0.122347  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.236942 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.176530  [    0/  100]\n",
      "loss: 0.145200  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.237820 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.247190  [    0/  100]\n",
      "loss: 0.089407  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.236087 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.169863  [    0/  100]\n",
      "loss: 0.113709  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.235204 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.086568  [    0/  100]\n",
      "loss: 0.127141  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.235563 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.103292  [    0/  100]\n",
      "loss: 0.277910  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.234114 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.196628  [    0/  100]\n",
      "loss: 0.225002  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.233899 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.233602  [    0/  100]\n",
      "loss: 0.122338  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.233027 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.084813  [    0/  100]\n",
      "loss: 0.117077  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.233117 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.146225  [    0/  100]\n",
      "loss: 0.189051  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.233392 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.069625  [    0/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.048379  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.231580 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.098998  [    0/  100]\n",
      "loss: 0.114026  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.231011 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.277791  [    0/  100]\n",
      "loss: 0.054073  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.234017 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.076887  [    0/  100]\n",
      "loss: 0.260531  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.231343 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.217702  [    0/  100]\n",
      "loss: 0.080679  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.229610 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.173777  [    0/  100]\n",
      "loss: 0.152079  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.229142 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.058246  [    0/  100]\n",
      "loss: 0.098652  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.228601 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.159482  [    0/  100]\n",
      "loss: 0.164199  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.228152 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.055077  [    0/  100]\n",
      "loss: 0.183200  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.227651 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.062933  [    0/  100]\n",
      "loss: 0.171318  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.227181 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.180076  [    0/  100]\n",
      "loss: 0.124752  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.228529 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.106428  [    0/  100]\n",
      "loss: 0.081272  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.226365 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.172341  [    0/  100]\n",
      "loss: 0.179236  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.227665 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.109247  [    0/  100]\n",
      "loss: 0.047300  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.225715 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.282023  [    0/  100]\n",
      "loss: 0.160576  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.225772 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.092021  [    0/  100]\n",
      "loss: 0.143556  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.225252 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.062308  [    0/  100]\n",
      "loss: 0.077107  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.224032 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.077647  [    0/  100]\n",
      "loss: 0.065790  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.224555 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.283563  [    0/  100]\n",
      "loss: 0.122381  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.224922 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.078650  [    0/  100]\n",
      "loss: 0.114788  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.223001 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.174261  [    0/  100]\n",
      "loss: 0.162697  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.222357 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.020196  [    0/  100]\n",
      "loss: 0.067643  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.224224 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.018711  [    0/  100]\n",
      "loss: 0.099850  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.221505 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.141747  [    0/  100]\n",
      "loss: 0.113295  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.221728 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.178569  [    0/  100]\n",
      "loss: 0.027286  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.220730 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.155200  [    0/  100]\n",
      "loss: 0.112918  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.220280 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.081354  [    0/  100]\n",
      "loss: 0.020237  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.220293 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.074418  [    0/  100]\n",
      "loss: 0.135032  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.219450 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.085620  [    0/  100]\n",
      "loss: 0.156437  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.219514 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.062304  [    0/  100]\n",
      "loss: 0.055875  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.220015 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.159521  [    0/  100]\n",
      "loss: 0.290811  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.218528 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.040410  [    0/  100]\n",
      "loss: 0.054674  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.217904 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.083315  [    0/  100]\n",
      "loss: 0.081839  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.217592 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.108045  [    0/  100]\n",
      "loss: 0.095978  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.217769 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.078979  [    0/  100]\n",
      "loss: 0.068575  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.216881 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.270382  [    0/  100]\n",
      "loss: 0.092169  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.216376 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.179462  [    0/  100]\n",
      "loss: 0.106093  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.216901 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.060845  [    0/  100]\n",
      "loss: 0.070207  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.217196 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.151378  [    0/  100]\n",
      "loss: 0.069877  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.215792 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.244562  [    0/  100]\n",
      "loss: 0.030674  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.215150 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.152860  [    0/  100]\n",
      "loss: 0.050208  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.215536 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.179512  [    0/  100]\n",
      "loss: 0.339475  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.214204 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.037034  [    0/  100]\n",
      "loss: 0.210224  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.213865 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.102888  [    0/  100]\n",
      "loss: 0.215983  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.213499 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.173065  [    0/  100]\n",
      "loss: 0.063467  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.213182 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.149683  [    0/  100]\n",
      "loss: 0.105048  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.213034 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.219135  [    0/  100]\n",
      "loss: 0.167166  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.212448 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.227300  [    0/  100]\n",
      "loss: 0.069276  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.212757 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.167264  [    0/  100]\n",
      "loss: 0.035630  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.211923 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.068001  [    0/  100]\n",
      "loss: 0.039712  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.212436 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.162263  [    0/  100]\n",
      "loss: 0.180166  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.211199 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.070723  [    0/  100]\n",
      "loss: 0.122375  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.210781 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.181074  [    0/  100]\n",
      "loss: 0.177563  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.211374 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.160955  [    0/  100]\n",
      "loss: 0.033913  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.210805 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.094742  [    0/  100]\n",
      "loss: 0.078527  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.209961 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.096609  [    0/  100]\n",
      "loss: 0.121275  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.209522 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.053041  [    0/  100]\n",
      "loss: 0.055810  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.210347 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.064519  [    0/  100]\n",
      "loss: 0.156286  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.209141 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.072860  [    0/  100]\n",
      "loss: 0.016238  [   50/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.208952 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.148380  [    0/  100]\n",
      "loss: 0.302428  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.208257 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.118833  [    0/  100]\n",
      "loss: 0.122777  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.207963 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.130785  [    0/  100]\n",
      "loss: 0.086744  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.207882 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.041190  [    0/  100]\n",
      "loss: 0.192890  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.208005 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.088452  [    0/  100]\n",
      "loss: 0.174067  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.207712 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.120411  [    0/  100]\n",
      "loss: 0.152526  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.206773 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.223568  [    0/  100]\n",
      "loss: 0.055085  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.207376 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.074887  [    0/  100]\n",
      "loss: 0.039956  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.206298 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.077368  [    0/  100]\n",
      "loss: 0.321652  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.205885 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.087603  [    0/  100]\n",
      "loss: 0.189774  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.206094 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.045405  [    0/  100]\n",
      "loss: 0.350071  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.205519 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.103100  [    0/  100]\n",
      "loss: 0.039510  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.205175 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.057968  [    0/  100]\n",
      "loss: 0.142544  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.204842 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.081997  [    0/  100]\n",
      "loss: 0.161324  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.204635 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.045780  [    0/  100]\n",
      "loss: 0.067462  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.204223 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.169902  [    0/  100]\n",
      "loss: 0.041523  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.203992 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.113772  [    0/  100]\n",
      "loss: 0.186449  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.203852 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.146022  [    0/  100]\n",
      "loss: 0.057183  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.204695 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.068296  [    0/  100]\n",
      "loss: 0.040534  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.203557 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.104566  [    0/  100]\n",
      "loss: 0.060686  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.202971 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.038418  [    0/  100]\n",
      "loss: 0.136287  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.202662 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.043787  [    0/  100]\n",
      "loss: 0.106415  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.202570 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.094852  [    0/  100]\n",
      "loss: 0.201896  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.203417 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.040826  [    0/  100]\n",
      "loss: 0.046309  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.202063 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.124654  [    0/  100]\n",
      "loss: 0.062681  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.201896 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.052996  [    0/  100]\n",
      "loss: 0.203032  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.201353 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.086256  [    0/  100]\n",
      "loss: 0.126772  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.201129 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.037136  [    0/  100]\n",
      "loss: 0.170491  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.200823 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.045737  [    0/  100]\n",
      "loss: 0.051691  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.200690 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.070013  [    0/  100]\n",
      "loss: 0.058204  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.200575 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.112506  [    0/  100]\n",
      "loss: 0.060299  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.200350 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.101913  [    0/  100]\n",
      "loss: 0.133265  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.199888 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.099645  [    0/  100]\n",
      "loss: 0.069621  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.199613 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.055103  [    0/  100]\n",
      "loss: 0.080090  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.199867 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.035841  [    0/  100]\n",
      "loss: 0.065308  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.199153 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.101679  [    0/  100]\n",
      "loss: 0.183211  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.200294 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.062757  [    0/  100]\n",
      "loss: 0.114866  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.198679 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.221041  [    0/  100]\n",
      "loss: 0.080385  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.200448 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.118227  [    0/  100]\n",
      "loss: 0.155454  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.198598 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.027443  [    0/  100]\n",
      "loss: 0.113534  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.197995 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.099338  [    0/  100]\n",
      "loss: 0.040158  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.198481 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.195247  [    0/  100]\n",
      "loss: 0.153463  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.197556 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.054660  [    0/  100]\n",
      "loss: 0.067230  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.197568 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.121338  [    0/  100]\n",
      "loss: 0.170554  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.197772 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.023254  [    0/  100]\n",
      "loss: 0.144951  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.196904 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.025518  [    0/  100]\n",
      "loss: 0.233534  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.196845 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.059526  [    0/  100]\n",
      "loss: 0.143679  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.196480 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.034563  [    0/  100]\n",
      "loss: 0.064908  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.196440 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.073254  [    0/  100]\n",
      "loss: 0.181976  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.196484 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.104067  [    0/  100]\n",
      "loss: 0.072889  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.195863 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.088175  [    0/  100]\n",
      "loss: 0.127856  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.196357 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.182432  [    0/  100]\n",
      "loss: 0.017887  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.195437 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.027217  [    0/  100]\n",
      "loss: 0.266164  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.196241 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.102320  [    0/  100]\n",
      "loss: 0.071362  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.195038 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.131518  [    0/  100]\n",
      "loss: 0.131704  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.194934 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.273656  [    0/  100]\n",
      "loss: 0.096723  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.194946 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.022434  [    0/  100]\n",
      "loss: 0.275211  [   50/  100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.194442 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.020643  [    0/  100]\n",
      "loss: 0.145179  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.194455 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.219694  [    0/  100]\n",
      "loss: 0.090088  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.194121 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.027053  [    0/  100]\n",
      "loss: 0.097323  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.193864 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.086908  [    0/  100]\n",
      "loss: 0.019273  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.195904 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.059687  [    0/  100]\n",
      "loss: 0.021817  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.193610 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.110728  [    0/  100]\n",
      "loss: 0.124792  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.193358 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.050314  [    0/  100]\n",
      "loss: 0.039241  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.193532 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.099159  [    0/  100]\n",
      "loss: 0.070517  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.192912 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.087016  [    0/  100]\n",
      "loss: 0.039955  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.193178 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.050378  [    0/  100]\n",
      "loss: 0.081163  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.192999 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.178902  [    0/  100]\n",
      "loss: 0.115147  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.192394 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.044317  [    0/  100]\n",
      "loss: 0.226247  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.192489 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.063478  [    0/  100]\n",
      "loss: 0.076684  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.193215 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.020724  [    0/  100]\n",
      "loss: 0.079179  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.192099 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.143388  [    0/  100]\n",
      "loss: 0.057733  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.191828 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.063477  [    0/  100]\n",
      "loss: 0.078970  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.192446 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.008703  [    0/  100]\n",
      "loss: 0.019397  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.192239 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.025009  [    0/  100]\n",
      "loss: 0.016295  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.191162 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.064701  [    0/  100]\n",
      "loss: 0.113080  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.191437 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.074232  [    0/  100]\n",
      "loss: 0.082808  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.190890 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.148778  [    0/  100]\n",
      "loss: 0.149872  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.191393 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.075940  [    0/  100]\n",
      "loss: 0.130477  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.190501 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.100335  [    0/  100]\n",
      "loss: 0.186691  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.190776 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.038088  [    0/  100]\n",
      "loss: 0.026574  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.190210 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.040478  [    0/  100]\n",
      "loss: 0.121469  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.189975 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.020586  [    0/  100]\n",
      "loss: 0.066118  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.189946 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.122890  [    0/  100]\n",
      "loss: 0.015229  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.191662 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.121553  [    0/  100]\n",
      "loss: 0.028626  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.189499 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.145365  [    0/  100]\n",
      "loss: 0.229981  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.189317 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.068490  [    0/  100]\n",
      "loss: 0.080209  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.189591 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.088471  [    0/  100]\n",
      "loss: 0.135001  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188994 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.023466  [    0/  100]\n",
      "loss: 0.079177  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188950 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.032631  [    0/  100]\n",
      "loss: 0.072809  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188683 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.043166  [    0/  100]\n",
      "loss: 0.074382  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188674 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.132025  [    0/  100]\n",
      "loss: 0.228683  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188377 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.016298  [    0/  100]\n",
      "loss: 0.132805  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188232 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.112804  [    0/  100]\n",
      "loss: 0.029591  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.188387 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.161932  [    0/  100]\n",
      "loss: 0.210797  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.188128 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.154435  [    0/  100]\n",
      "loss: 0.023045  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.188331 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.019203  [    0/  100]\n",
      "loss: 0.051274  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.187650 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.058924  [    0/  100]\n",
      "loss: 0.057179  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.187733 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.077082  [    0/  100]\n",
      "loss: 0.055852  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.187492 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.021662  [    0/  100]\n",
      "loss: 0.072637  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.188660 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.033809  [    0/  100]\n",
      "loss: 0.047218  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.187317 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.141338  [    0/  100]\n",
      "loss: 0.198918  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.186909 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.024866  [    0/  100]\n",
      "loss: 0.038404  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.186768 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.112384  [    0/  100]\n",
      "loss: 0.200982  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.186740 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.031129  [    0/  100]\n",
      "loss: 0.186134  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.186551 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.132965  [    0/  100]\n",
      "loss: 0.028758  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.188196 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.056026  [    0/  100]\n",
      "loss: 0.015604  [   50/  100]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.186376 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(iris_dataset_train_dataLoader, model, loss_fn, optimizer)\n",
    "    test_loop(iris_dataset_test_dataLoader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Output: tensor([[  7.8716,   3.4911,  -9.3152],\n",
      "        [ -5.3199,   2.2753,   2.7754],\n",
      "        [ 10.1128,   4.2297, -11.7181],\n",
      "        [  7.5311,   3.3707,  -8.9504],\n",
      "        [ -1.5482,   2.8065,  -0.8991]], grad_fn=<MmBackward>)\n",
      "Probabilities: tensor([[9.8763e-01, 1.2365e-02, 3.3921e-08],\n",
      "        [1.8980e-04, 3.7745e-01, 6.2236e-01],\n",
      "        [9.9722e-01, 2.7786e-03, 3.2944e-10],\n",
      "        [9.8464e-01, 1.5361e-02, 6.8464e-08],\n",
      "        [1.2383e-02, 9.6392e-01, 2.3699e-02]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted class: tensor([0, 2, 0, 0, 1])\n",
      "True class: tensor([0, 2, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_X, batch_y = next(iter(iris_dataset_test_dataLoader))\n",
    "\n",
    "results = model(batch_X.float().to(device))\n",
    "print(f'Network Output: {results}')\n",
    "\n",
    "#convert the results to probabilities\n",
    "pred_probab = nn.Softmax(dim=1)(results)\n",
    "print(f'Probabilities: {pred_probab}')\n",
    "\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "print(f'True class: {batch_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
